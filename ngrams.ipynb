{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-grams are combinations of tokenized words from a document or even a corpus.  I then apply a Counter function that takes a integer parameter and finds the most common sequences of words of that number of words.  So if we pass 4, we find the most common combinations of four words returned as a tuple.  Because order does not matter, we are bound to see some repetition of similar variations of phrases just with different endings and beginning words.  4 seems to be a sweet spot of the right balance between finding a phrase with the minimum amount of information where it can include a subject, verb (inifinive and continuous verbs requiring to seperate tokens), preposition, and possibly object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "  \n",
    "# Opening JSON file \n",
    "with open('char_corps.json', 'r') as openfile: \n",
    "  \n",
    "    # Reading from json file \n",
    "    corpuses = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_corps={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import collections\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenize(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "picard = corpuses['PICARD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('mister', 'la', 'forge'), 203),\n",
       " (('i', 'want', 'you'), 86),\n",
       " (('make', 'it', 'so'), 79),\n",
       " (('want', 'you', 'to'), 76),\n",
       " (('i', 'want', 'to'), 61),\n",
       " (('this', 'is', 'the'), 59),\n",
       " (('you', 'have', 'the'), 57),\n",
       " (('what', 'is', 'it'), 53),\n",
       " (('picard', 'of', 'the'), 53),\n",
       " (('we', 'have', 'to'), 52),\n",
       " (('what', 'do', 'you'), 51),\n",
       " (('captain', 'jeanluc', 'picard'), 47),\n",
       " (('as', 'soon', 'as'), 46),\n",
       " (('this', 'is', 'captain'), 46),\n",
       " (('i', 'would', 'like'), 45)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_counts = Counter(ngrams(picard.split(), 3))\n",
    "ngram_counts.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('i', 'want', 'you', 'to'), 73),\n",
       " (('you', 'have', 'the', 'bridge'), 45),\n",
       " (('jeanluc', 'picard', 'of', 'the'), 40),\n",
       " (('captain', 'jeanluc', 'picard', 'of'), 37),\n",
       " (('i', 'would', 'like', 'to'), 32),\n",
       " (('take', 'us', 'out', 'of'), 29),\n",
       " (('the', 'bridge', 'number', 'one'), 28),\n",
       " (('this', 'is', 'the', 'captain'), 25),\n",
       " (('im', 'on', 'my', 'way'), 23),\n",
       " (('have', 'the', 'bridge', 'number'), 23),\n",
       " (('this', 'is', 'captain', 'jeanluc'), 22),\n",
       " (('is', 'captain', 'jeanluc', 'picard'), 22),\n",
       " (('this', 'is', 'captain', 'picard'), 21),\n",
       " (('in', 'my', 'ready', 'room'), 21),\n",
       " (('a', 'course', 'for', 'the'), 21)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_counts = Counter(ngrams(picard.split(), 4))\n",
    "ngram_counts.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('you', 'have', 'the', 'bridge', 'number', 'one'), 23),\n",
       " (('this', 'is', 'captain', 'jeanluc', 'picard', 'of'), 21),\n",
       " (('is', 'captain', 'jeanluc', 'picard', 'of', 'the'), 21),\n",
       " (('captain', 'jeanluc', 'picard', 'of', 'the', 'federation'), 15),\n",
       " (('jeanluc', 'picard', 'of', 'the', 'federation', 'starship'), 14),\n",
       " (('picard', 'of', 'the', 'federation', 'starship', 'enterprise'), 12),\n",
       " (('captain', 'jeanluc', 'picard', 'of', 'the', 'uss'), 10),\n",
       " (('jeanluc', 'picard', 'of', 'the', 'uss', 'enterprise'), 9),\n",
       " (('captain', 'jeanluc', 'picard', 'of', 'the', 'enterprise'), 8),\n",
       " (('i', 'am', 'captain', 'jeanluc', 'picard', 'of'), 8),\n",
       " (('am', 'captain', 'jeanluc', 'picard', 'of', 'the'), 8),\n",
       " (('this', 'is', 'my', 'first', 'officer', 'commander'), 7),\n",
       " (('my', 'first', 'officer', 'commander', 'william', 'riker'), 7),\n",
       " (('mister', 'data', 'you', 'have', 'the', 'bridge'), 7),\n",
       " (('number', 'one', 'you', 'have', 'the', 'bridge'), 7)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_counts = Counter(ngrams(picard.split(), 6))\n",
    "ngram_counts.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing around with the count of ngrams can give some interesting information but it seems like Picards most used line with different variation is when introducing himself as the Captain of the Enterprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('were', 'going', 'to', 'have', 'to'), 11),\n",
       " (('get', 'us', 'out', 'of', 'here'), 9),\n",
       " (('take', 'us', 'out', 'of', 'orbit'), 7),\n",
       " (('riker', 'of', 'the', 'uss', 'enterprise'), 6),\n",
       " (('lets', 'get', 'out', 'of', 'here'), 6),\n",
       " (('me', 'on', 'the', 'away', 'team'), 5),\n",
       " (('commander', 'william', 'riker', 'of', 'the'), 5),\n",
       " (('william', 'riker', 'of', 'the', 'uss'), 5),\n",
       " (('what', 'the', 'hell', 'is', 'going'), 5),\n",
       " (('the', 'hell', 'is', 'going', 'on'), 5)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Riker = corpuses['RIKER']\n",
    "ngram_counts = Counter(ngrams(Riker.split(), 5))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('i', 'do', 'not', 'believe'), 38),\n",
       " (('i', 'do', 'not', 'know'), 36),\n",
       " (('it', 'appears', 'to', 'be'), 35),\n",
       " (('i', 'do', 'not', 'understand'), 21),\n",
       " (('i', 'am', 'unable', 'to'), 18),\n",
       " (('i', 'am', 'attempting', 'to'), 18),\n",
       " (('i', 'believe', 'i', 'have'), 17),\n",
       " (('appears', 'to', 'be', 'a'), 17),\n",
       " (('i', 'am', 'an', 'android'), 16),\n",
       " (('i', 'would', 'like', 'to'), 13)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = corpuses['DATA']\n",
    "ngram_counts = Counter(ngrams(Data.split(), 4))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laforge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('la', 'forge', 'to', 'bridge'), 28),\n",
       " (('going', 'to', 'have', 'to'), 21),\n",
       " (('might', 'be', 'able', 'to'), 16),\n",
       " (('should', 'be', 'able', 'to'), 15),\n",
       " (('take', 'a', 'look', 'at'), 15),\n",
       " (('were', 'going', 'to', 'have'), 14),\n",
       " (('i', 'dont', 'think', 'so'), 12),\n",
       " (('are', 'you', 'all', 'right'), 11),\n",
       " (('a', 'look', 'at', 'this'), 11),\n",
       " (('its', 'going', 'to', 'take'), 11)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LaForge = corpuses['LAFORGE']\n",
    "ngram_counts = Counter(ngrams(LaForge.split(), 4))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('we', 'are', 'being', 'hailed'), 15),\n",
       " (('i', 'am', 'picking', 'up'), 12),\n",
       " (('aye', 'sir', 'aye', 'sir'), 10),\n",
       " (('what', 'are', 'you', 'doing'), 9),\n",
       " (('captain', 'we', 'are', 'being'), 9),\n",
       " (('captain', 'i', 'am', 'picking'), 8),\n",
       " (('are', 'you', 'all', 'right'), 8),\n",
       " (('worf', 'to', 'captain', 'picard'), 8),\n",
       " (('i', 'do', 'not', 'know'), 8),\n",
       " (('the', 'borg', 'ship', 'is'), 7)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Worf = corpuses['WORF']\n",
    "ngram_counts = Counter(ngrams(Worf.split(), 4))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('going', 'to', 'have', 'to'), 14),\n",
       " (('i', 'want', 'you', 'to'), 10),\n",
       " (('might', 'be', 'able', 'to'), 10),\n",
       " (('how', 'do', 'you', 'feel'), 8),\n",
       " (('id', 'like', 'you', 'to'), 7),\n",
       " (('all', 'over', 'the', 'ship'), 7),\n",
       " (('im', 'not', 'sure', 'i'), 6),\n",
       " (('take', 'a', 'look', 'at'), 6),\n",
       " (('i', 'dont', 'know', 'what'), 6),\n",
       " (('going', 'to', 'be', 'all'), 6)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crusher = corpuses['CRUSHER']\n",
    "ngram_counts = Counter(ngrams(Crusher.split(), 4))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Troi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('what', 'are', 'you', 'doing'), 11),\n",
       " (('i', 'dont', 'know', 'what'), 10),\n",
       " (('a', 'great', 'deal', 'of'), 10),\n",
       " (('are', 'you', 'all', 'right'), 7),\n",
       " (('i', 'want', 'you', 'to'), 7),\n",
       " (('i', 'thought', 'you', 'might'), 6),\n",
       " (('what', 'do', 'you', 'mean'), 6),\n",
       " (('we', 'have', 'to', 'get'), 6),\n",
       " (('this', 'is', 'counsellor', 'troi'), 5),\n",
       " (('you', 'dont', 'have', 'to'), 5)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "troi = corpuses['TROI']\n",
    "ngram_counts = Counter(ngrams(troi.split(), 4))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('no', 'no', 'no', 'no'), 5),\n",
       " (('you', 'are', 'out', 'of'), 4),\n",
       " (('are', 'out', 'of', 'order'), 4),\n",
       " (('temper', 'temper', 'mon', 'capitaine'), 4),\n",
       " (('put', 'an', 'end', 'to'), 3),\n",
       " (('a', 'dangerous', 'savage', 'child'), 3),\n",
       " (('dangerous', 'savage', 'child', 'race'), 3),\n",
       " (('will', 'not', 'be', 'harmed'), 3),\n",
       " (('than', 'you', 'can', 'possibly'), 3),\n",
       " (('you', 'can', 'possibly', 'imagine'), 3)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = corpuses['Q']\n",
    "ngram_counts = Counter(ngrams(Q.split(), 4))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wesley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('what', 'are', 'you', 'doing'), 5),\n",
       " (('aye', 'sir', 'aye', 'sir'), 5),\n",
       " (('i', 'dont', 'know', 'what'), 5),\n",
       " (('i', 'dont', 'think', 'so'), 5),\n",
       " (('a', 'look', 'at', 'the'), 4),\n",
       " (('look', 'at', 'the', 'bridge'), 4),\n",
       " (('what', 'do', 'you', 'think'), 4),\n",
       " (('sir', 'yes', 'sir', 'commander'), 3),\n",
       " (('i', 'think', 'i', 'can'), 3),\n",
       " (('yes', 'sir', 'yes', 'sir'), 3)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wesley = corpuses['WESLEY']\n",
    "ngram_counts = Counter(ngrams(wesley.split(), 4))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = picard + Riker + Data + Worf + LaForge + Crusher + troi + Q + wesley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('i', 'want', 'you', 'to'), 111),\n",
       " (('are', 'you', 'all', 'right'), 75),\n",
       " (('going', 'to', 'have', 'to'), 70),\n",
       " (('i', 'would', 'like', 'to'), 57),\n",
       " (('what', 'are', 'you', 'doing'), 55),\n",
       " (('you', 'have', 'the', 'bridge'), 51),\n",
       " (('might', 'be', 'able', 'to'), 48),\n",
       " (('i', 'do', 'not', 'believe'), 48),\n",
       " (('what', 'do', 'you', 'think'), 46),\n",
       " (('it', 'appears', 'to', 'be'), 44)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_counts = Counter(ngrams(all_text.split(), 4))\n",
    "ngram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
