{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for text files\n",
    "directory = \"C:/Users/Ben/Documents/Star Trek/raw_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seperate text file for each season to store the dialogue.\n",
    "\n",
    "with open('season1ep101.txt', 'a') as file:\n",
    "    farpoint_url = \"http://www.chakoteya.net/NextGen/101.htm\"\n",
    "    farpoint_html = urllib.request.urlopen(farpoint_url).read().decode('utf-8')\n",
    "    farpoint_text = get_text(farpoint_html)\n",
    "    file.write(farpoint_text.rstrip(\"\\n\"))\n",
    "file.close()\n",
    "\n",
    "for i in range(103,127):\n",
    "    with open('raw_text/1.{}.txt'.format(i), 'a') as file:\n",
    "        url = \"http://www.chakoteya.net/NextGen/{}.htm\".format(i)\n",
    "        html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "        text = get_text(html)\n",
    "        file.write(text.rstrip(\"\\n\"))\n",
    "    file.close()\n",
    "    \n",
    "for i in range(127,149):\n",
    "    with open('raw_text/2.{}.txt'.format(i), 'a') as file:\n",
    "        url = \"http://www.chakoteya.net/NextGen/{}.htm\".format(i)\n",
    "        html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "        text = get_text(html)\n",
    "        file.write(text.rstrip(\"\\n\"))\n",
    "    file.close()\n",
    "    \n",
    "for i in range(149,175):\n",
    "    with open('raw_text/3.{}.txt'.format(i), 'a') as file:\n",
    "        url = \"http://www.chakoteya.net/NextGen/{}.htm\".format(i)\n",
    "        html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "        text = get_text(html)\n",
    "        file.write(text.rstrip(\"\\n\"))\n",
    "    file.close()\n",
    "    \n",
    "for i in range(175,201):\n",
    "    with open('raw_text/4.{}.txt'.format(i), 'a') as file:\n",
    "        url = \"http://www.chakoteya.net/NextGen/{}.htm\".format(i)\n",
    "        html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "        text = get_text(html)\n",
    "        file.write(text.rstrip(\"\\n\"))\n",
    "    file.close()\n",
    "    \n",
    "for i in range(201,227):\n",
    "    with open('raw_text/5.{}.txt'.format(i), 'a') as file:\n",
    "        url = \"http://www.chakoteya.net/NextGen/{}.htm\".format(i)\n",
    "        html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "        text = get_text(html)\n",
    "        file.write(text.rstrip(\"\\n\"))\n",
    "    file.close()\n",
    "    \n",
    "for i in range(227,253):\n",
    "    with open('raw_text/6.{}.txt'.format(i), 'a') as file:\n",
    "        url = \"http://www.chakoteya.net/NextGen/{}.htm\".format(i)\n",
    "        html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "        text = get_text(html)\n",
    "        file.write(text.rstrip(\"\\n\"))\n",
    "    file.close()\n",
    "    \n",
    "for i in range(253,278):\n",
    "    with open('raw_text/7.{}.txt'.format(i), 'a') as file:\n",
    "        url = \"http://www.chakoteya.net/NextGen/{}.htm\".format(i)\n",
    "        html = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "        text = get_text(html)\n",
    "        file.write(text.rstrip(\"\\n\"))\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to open the text files\n",
    "def opn(file_name):\n",
    "    '''\n",
    "    Transforms a text file to a list of lists, each entry being a line of the text. \n",
    "    input: str. path to the chapter file eg. \"1.0.txt\"\n",
    "       output: a list containing each line of the text as a list'''\n",
    "    with open(file_name) as file:  \n",
    "        l = []\n",
    "        for line in file:\n",
    "            l.append(list(line.rstrip().split(' '' ')))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us clean some extra lines that we created while splitting\n",
    "def clean(l):\n",
    "    '''\n",
    "    Cleans the '['']' that were created by the opn function\n",
    "    input: List of each line as a list.\n",
    "       output: A cleaned list wihtout empty entries.  Also replace text in parenthesis with \"\"'''\n",
    "    for line in l:\n",
    "        if line == ['']:\n",
    "            l.remove(line)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to separate get the character and dialogue\n",
    "\n",
    "def transform_to_data(l, file_name):\n",
    "    '''\n",
    "    Generates a list of ordered tuples (Character, dialogue, chapter, season).\n",
    "    input: A list of text, each entry being a line of text.\n",
    "    output: A list of order tuples eg. [(Character, dialogue, chapter, season),\n",
    "                                        (Character, dialogue, chapter, season)] '''\n",
    "    ep = int(file_name[2:5]) - 100 #Get episode number from filename.  The episodes were numbered starting at 101 on the site\n",
    "    seas = int(file_name[0]) #Get season from filename\n",
    "    #Initialize lists (columns) to contain the data for each dialogue (rows)\n",
    "    charac = []\n",
    "    dialogue = []\n",
    "    season = []\n",
    "    episode = []\n",
    "    #location = []\n",
    "    for i in l:\n",
    "        for j in i[0]:\n",
    "            if j == ':': #If we find a ':' we know there is a dialogue and a character in that line\n",
    "                season.append(seas) #We take season\n",
    "                episode.append(ep) #We take chapter\n",
    "                stop_point = i[0].index(j) #We get the stop point so we know where to slice the line\n",
    "                charac.append(i[0][:stop_point]) #Everything before the stop point is the Character\n",
    "                dialogue.append(i[0][stop_point+1:]) # And everything after is the dialogue\n",
    "\n",
    "    return list(zip(charac,dialogue,season,episode)) # We zip all our data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame() #Initialize a dataframe\n",
    "\n",
    "#We start the extraction from our directory\n",
    "for filename in os.listdir(directory):\n",
    "    if '.txt' in filename:\n",
    "        f = opn('raw_text/' + filename)\n",
    "        f = clean(f)\n",
    "        #We append the rows to our dataframe\n",
    "        append_me =  pd.DataFrame(data = transform_to_data(f, filename) , columns = ['Character','dialogue','season','chapter'])\n",
    "        data = data.append(append_me, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we save it \n",
    "data.to_csv('StarTrekTNG_test.csv', index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
